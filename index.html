<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>L-RPG by KCL-Planning</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">L-RPG</h1>
      <h2 class="project-tagline">Towards more scalable Planning Systems</h2>
	  <a href="index.html" class="btn">L-RPG</a>
	  <a href="publications.html" class="btn">Publications</a>
      <a href="https://github.com/KCL-Planning/L-RPG" class="btn">View on GitHub</a>
      <a href="https://github.com/KCL-Planning/L-RPG/tarball/master" class="btn">Download .tar.gz</a>
	  <a href="contact.html" class="btn">Contact</a>
    </section>

    <section class="main-content">
      <h3>
<a id="an-introduction" class="anchor" href="#an-introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>An introduction.</h3>

<p>L-RPG is a <i>lifted planner</i> that does not rely on grounding to solve planning instances, unlike most modern planners -- like FF and FastDownward -- that ground before planning starts. Not grounding is a dual-edged sword:</p>

<p>
Pros:
<ul>
<li>We safe a lot of memory which allows us to tackle larger problem instances.</li>
<li>The techniques we use allows us to calculate heuristics faster.</li>
</ul>
</p>
<p>
Cons:
<ul>
<li>We get weaker heuristic estimates.</li>
<li>There is an overhead to create successor states.</li>
</ul>
</p>
<p>Indeed, planners that rely on fully grounding the domain can run out of memory during grounding! Some heuristics, like merge & shrink and pattern databases, bound the memory allowed. However, the construction of the data structures for these heuristics still requires grounding. Traditionally lifted heuristics have been very uninformative. For example, least-commitment Planners like UCPOP have used counting the number of open <i>flaws</i> or the number of <i>open conditions</i> as a heuristic estimate. L-RPG introduces an heuristic that is competitive with FF's RPG heuristic whilst not having to ground the entire domain.</p>

<h3>
<a id="equivalent-objects" class="anchor" href="#equivalent-objects" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Equivalent Objects</h3>

<p>Consider the <i>Driverlog</i> problem instance depicted in <a href="#driverlog-problem-img">Figure 1</a>. The trucks t2 and t3 start at the same location, are empty, and are not being driven by a driver. It is clear that when constructing an <i>Relaxed Planning Graph</i> the  same  set  of  actions  will  be  applied  to all these trucks and that any fact that is reachable for one truck (e.g. <b>(at t2 s3)</b> ) will also be reachable for any of the other trucks (e.g. <b>(at t3 s3)</b> ). These trucks are <i>equivalent</i>, so we can substitute these instances with a new object T. This reduces the size of the RPG considerably because instead of dealing with these two trucks separately we now only need to consider one.</p>

<p>Just as the trucks in can be made equivalent, it is clear that although the instances of type driver – d1, d2, d3, and d4 – are not at the same location in the initial state they can become <i>equivalent</i> too. This is  because all these drivers can reach the same locations and board the same trucks, any fact that is reachable for one driver is also reachable for the other drivers. Finding and exploiting these <i>equivalence relationships</i> between objects are key to L-RPG.</p>

<center>
<img src="images/driverlog-problem.png" id="driverlog-problem-img"></img>
<figcaption>Figure 1: A simple Driverlog problem instanced. The dashed lines can be traversed by drivers and the solid lines can be traversed by trucks.</figcaption>
</center>

<p>Details of how these equivalence relationships are found are in <a href="">the paper</a>. In general we use <a href="https://www.google.co.uk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&cad=rja&uact=8&ved=0ahUKEwjOpYO1t_XNAhUEBsAKHV-wAcMQFggzMAc&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1105.5451&usg=AFQjCNFxa0hHFpnOEtvCU64suBGRcigwtQ&sig2=mLXg7jlZTh-GhViJfb96aQ">TIM</a> to infer sets of objects that could become equivalent. These <i>equivalence sets</i> are then used during the <a href="#constructing-the-rpg">construction of the RPG</a>.</p>

<h3>
<a id="constructing-the-rpg" class="anchor" href="#constructing-the-rpg" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Constructing the RPG</h3>
<p>To construct the RPG we used partially-grounded actions. Actions are grounded according to the equivalence sets found during the TIM analysis. For example, the following <b>drive</b> actions are created:

<ul>
<li><b>(drive {t1, t2, t3, t4} {s1} {s2})</b></li>
<li><b>(drive {t1, t2, t3, t4} {s2} {s1})</b></li>
</ul>

The trucks are part of the same <i>equivalence set</i> whilst the locations are not. We construct the RPG much like FF does with these partially-grounded actions. The key difference is that we check at each fact layer which objects have become equivalent and <i>merge</i> them. For example, <b>t2</b> and <b>t3</b> are equivalent in the initial fact layer and are merged into a single object. Similarly, after creating the second fact layer we can merge <b>d1</b> and <b>d2</b>, because (1) They are part of the same <i>equivalence set</i> and; (2) Have reached each others initial state: <b>(at d1 s1)</b> and <b>(at d2 p1)</b>, respectively. The constructed RPG is depicted in <a href="#lifted-rpg-img">Figure 2</a>.

<p></p>
<center>
<img src="images/lifted-rpg.png" id="lifted-rpg-img"></img>
<figcaption>Figure 2: The lifted RPG for the Driverlog problem, NOOPs have been omitted. T = {t1,t2,t3,t4}; D= {d1,d2,d3,d4}.</figcaption>
</center>
</p>

<h3>
<a id="calculating-the-heuristic" class="anchor" href="#calculating-the-heuristic" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Calculating the heuristic</h3>
<p>Given a constructed Lifted Relaxed Planning Graph (L-RPG) we extract a relaxed lifted plan much like FF. Unfortunately, this yields very poor heuristics, much like previous lifted heuristics. The reason is the merging of <i>equivalent objects</i> during the construction of the RPG. For example, if the goal is <b>(driving d1 t2)</b> then we can see in <a href="#lifted-rpg-img">Figure 2</a> that this fact is achieved in the 2nd fact layer by applying the action <b>(board {d1, d2, d3, d4} {t1, t2, t3, t4} s1)</b>, giving a heuristic estimate of 1.</p>

<p>The problem is that in the 2nd fact layer the drivers <b>d1</b> and <b>d2</b> become equivalent, this means that because <b>d2</b> can board <b>t2</b> so can <b>t1</b>. In short during the extraction of a relaxed plan from the L-RPG we substituted <b>d1</b> for <b>d2</b>. To augment the heuristic we <i>instantiate</i> the applied action, which means we take the intersection of the variable domains of the action's parameters and the fact we want to achieve (in this case <b>(driving d1 t2)</b>). This gives us <b>(board {d1} {t2} s1)</b>. Then we check its preconditions with the previous fact layer and see if any of the variable domains become empty. The fact <b>(at t2 s1)</b> is true in the initial fact layer, but <b>(at d1 s1)</b> is not.</p>

<p>We have experimented with two ways to augment the heuristic:

<ul>
<li>ObjectSub: Find the first layer where the objects (in this case <b>d1</b> and <b>d2</b>) become equivalent and add that fact layer to the heuristic.</li>
<li>GoalSub: Add the violated precondition (in this case <b>(at d1 s1)</b>) as a new goal and find a relaxed plan to achieve it.
</ul>
</p>

<h3>
<a id="further-improvements" class="anchor" href="#further-improvements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Further improvements</h3>
<p>In addition we have created two more additions to L-RPG to improve it.

<ul>
<li>Preserve goals: We try to construct an L-RPG that does not include any actions that could delete any goals that have previous been achieved. If we cannot find a relaxed plan then we relax this constraint and rebuild the full L-RPG.</li>
<li>Helpful actions: Like FF we use helpful actions to prune the search space.
</ul>
</p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h3>
<p>The results of L-RPG compared to FF are depicted in <a href=#results-img">Figure 3</a>. As we can see the version that does not use any substitution performs very poorly. On the other hand the GoalSub with helpful actions and preservation of goals is very competitive and even outperforms FF on some domains.

<center>
<img src="images/results.png" id="results-img"></img>
<figcaption>Figure 3: Number of problems solved. <i>h</i> means helpful actions. <i>p</i> means that goals are preserved.</figcaption>
</center>
<p></p>

The memory results on larger problem instances is depicted in <a href="#large-results-img">Figure 4</a>. For these problem instances we added a lot more <i>resources</i> to the domain (rovers, satellites, drivers, and trucks). We see that our planner can solve large problem instances whereas FF dies whilst grounding.
<p></p>
<center>
<img src="images/large-results.png" id="large-results-img"></img>
<figcaption>Figure 4: Memory usage on large problem instances.</figcaption>
</center>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/KCL-Planning/L-RPG">L-rpg</a> is maintained by <a href="https://github.com/KCL-Planning">KCL-Planning</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
